{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Downloading ArcticDEM Strip Files from PGC\n",
    "\n",
    "This script automates the process of downloading **ArcticDEM Strip DEM files** using metadata provided in a CSV file. \n",
    "\n",
    "\n",
    "### Loads a CSV File\n",
    "- Reads `csv/ArcticDEM_Stripfiles_Basin.csv`, which contains DEM metadata and file paths\n",
    "\n",
    "### Constructs Download URLs\n",
    "- Base URL: `https://pgc-opendata-dems.s3.us-west-2.amazonaws.com/arcticdem/`\n",
    "- Builds full URLs for each `_dem.tif` file by manipulating the `fileurl` column\n",
    "\n",
    "### Sets Up Local Download Directory\n",
    "- Saves downloaded files in the `download_ArcticDEM_Stripfiles` folder\n",
    "\n",
    "### Downloads Files with Checks\n",
    "- Skips download if the file already exists and is larger than 10 MB\n",
    "- Uses `requests.get()` to stream and save each file\n",
    "- Handles and logs errors\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "file_path = 'csv/ArcticDEM_Stripfiles_Basin.csv'\n",
    "arcticdem_csv = pd.read_csv(file_path)\n",
    "\n",
    "# Base URL\n",
    "pgc_url_base = 'https://pgc-opendata-dems.s3.us-west-2.amazonaws.com/arcticdem/'\n",
    "\n",
    "# Extract file paths and form new URLs\n",
    "arcticdem_csv['pgc_url'] = pgc_url_base + arcticdem_csv['fileurl'].apply(lambda x: '/'.join(x.split('/')[7:])).str[:-7] + '_dem.tif'\n",
    "\n",
    "# Create a folder to store the downloaded files\n",
    "output_folder = '1_download'\n",
    "\n",
    "# Download each file\n",
    "for i, row in arcticdem_csv.iterrows():\n",
    "    file_url = row['pgc_url']\n",
    "    file_name = os.path.join(output_folder, os.path.basename(file_url))\n",
    "    \n",
    "    # Check if the file exists and is larger than 10MB\n",
    "    if os.path.exists(file_name) and os.path.getsize(file_name) > 10 * 1024 * 1024:\n",
    "        print(f\"Skipping (already downloaded and >10MB): {file_name}\")\n",
    "        continue  # Skip this file\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading: {file_url}\")\n",
    "        response = requests.get(file_url, stream=True)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        \n",
    "        # Save the file locally\n",
    "        with open(file_name, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "        print(f\"Saved: {file_name}\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download {file_url}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-landsat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
