{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-register ArcticDEM strip files using ICESat-2 elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.mask import mask\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.plot import plotting_extent\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import box\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry import shape\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyproj import Transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from affine import Affine\n",
    "import earthpy.plot as ep\n",
    "import rasterstats as rs\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "arcticdem_folder = \"ArcticDEM Processing/1_download\"\n",
    "artefact_folder = \"ArcticDEM Processing/masks/artefacts\"\n",
    "dynamic_mask_folder = \"ArcticDEM Processing/masks/dynamic\"\n",
    "clipped_dem_folder = \"ArcticDEM Processing/2_crop\"\n",
    "corrected_dem_folder = \"ArcticDEM Processing/3_co-register\"\n",
    "\n",
    "dynamic_mask_file = os.path.join(dynamic_mask_folder, \"dynamic_mask.shp\")\n",
    "alignment_aoi_file = os.path.join(\"ArcticDEM Processing/masks/plane/\", \"align_dem.shp\")\n",
    "icesat_atlo6 = \"ArcticDEM Processing/csv/merged_ATL06_march_may.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and mask the ArcticDEM data using artefact masks and dynamic mask \n",
    "(masking the dynamic movement of the collapse basin and ice dynamics e.g. crevassing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the align_plane shapefile\n",
    "align_plane = gpd.read_file(alignment_aoi_file)\n",
    "\n",
    "# Convert align_plane to a single geometry for intersection checks\n",
    "align_plane = align_plane.to_crs(\"EPSG:3413\")  # Change to match your DEM CRS\n",
    "align_plane_geom = align_plane.unary_union\n",
    "\n",
    "# Iterate over all ArcticDEM .tif files\n",
    "for dem_file in os.listdir(arcticdem_folder):\n",
    "    if dem_file.endswith(\".tif\"):\n",
    "        # Get paths\n",
    "        base_name = os.path.splitext(dem_file)[0]\n",
    "        artefact_file = os.path.join(artefact_folder, f\"artefact_{base_name}.shp\")\n",
    "        dem_path = os.path.join(arcticdem_folder, dem_file)\n",
    "        output_path = os.path.join(clipped_dem_folder, dem_file)\n",
    "\n",
    "        print(f\"Processing {dem_file}...\")\n",
    "        with rasterio.open(dem_path) as src:\n",
    "            # Check if raster contains valid data\n",
    "            data = src.read(1)  # Read the first band\n",
    "            if np.all(data == 0) or np.isnan(data).all():\n",
    "                print(f\"Skipping {dem_file}: No valid data.\")\n",
    "                continue\n",
    "\n",
    "            # Check if raster overlaps the align_plane\n",
    "            raster_bounds = box(*src.bounds)  # Convert raster bounds to a shapely box\n",
    "            if not raster_bounds.intersects(align_plane_geom):\n",
    "                print(f\"Skipping {dem_file}: No overlap with align_plane.\")\n",
    "                continue\n",
    "\n",
    "            # Align align_plane CRS with the raster\n",
    "            align_plane_geom = align_plane.to_crs(src.crs).unary_union\n",
    "\n",
    "            # Start with the original DEM\n",
    "            masked_image, masked_transform = src.read(), src.transform\n",
    "            meta = src.meta.copy()\n",
    " \n",
    "            # Check if the artefact file exists\n",
    "            if os.path.exists(artefact_file):\n",
    "                print(f\"Applying mask using {artefact_file}...\")\n",
    "                artefact_mask = gpd.read_file(artefact_file)\n",
    "                artefact_mask = artefact_mask.to_crs(src.crs)\n",
    "                mask_geom = [feature[\"geometry\"] for feature in artefact_mask.__geo_interface__[\"features\"]]\n",
    "\n",
    "                # Apply the artefact mask\n",
    "                masked_image, masked_transform = mask(src, mask_geom, invert=True, crop=False)\n",
    "                meta.update({\n",
    "                    \"height\": masked_image.shape[1],\n",
    "                    \"width\": masked_image.shape[2],\n",
    "                    \"transform\": masked_transform\n",
    "                })\n",
    "\n",
    "            # Clip to align_plane\n",
    "            print(f\"Clipping to align_plane bounding box...\")\n",
    "            with rasterio.io.MemoryFile() as memfile:\n",
    "                with memfile.open(**meta) as temp_raster:\n",
    "                    temp_raster.write(masked_image)\n",
    "                    clipped_image, clipped_transform = mask(temp_raster, [align_plane_geom], invert=False, crop=True)\n",
    "\n",
    "            # Update meta after clipping\n",
    "            meta.update({\n",
    "                \"height\": clipped_image.shape[1],\n",
    "                \"width\": clipped_image.shape[2],\n",
    "                \"transform\": clipped_transform\n",
    "            })\n",
    "\n",
    "        # Save the result\n",
    "        print(f\"Saving raster to {output_path}\")\n",
    "        with rasterio.open(output_path, \"w\", **meta) as dest:\n",
    "            dest.write(clipped_image)\n",
    "\n",
    "print(\"Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ICESat-2 ATL06 elevation points\n",
    "icesat_atlo6 = pd.read_csv(icesat_atlo6)\n",
    "\n",
    "# Create GeoDataFrame from DataFrame\n",
    "geometry = [Point(xy) for xy in zip(icesat_atlo6['longitude'], icesat_atlo6['latitude'])]\n",
    "icesat_march_may = gpd.GeoDataFrame(icesat_atlo6, geometry=geometry, crs=\"EPSG:4326\")  # Assuming WGS84\n",
    "\n",
    "# Import dynamic regions and study area mask\n",
    "mask_aoi = gpd.read_file(alignment_aoi_file)\n",
    "mask_dynamic = gpd.read_file(dynamic_mask_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the mask is in the same CRS as the points\n",
    "mask_aoi = mask_aoi.to_crs(icesat_march_may.crs) \n",
    "mask_dynamic = mask_dynamic.to_crs(icesat_march_may.crs)\n",
    "\n",
    "# Check the shapefiles have the same crs\n",
    "print(f\"Plane mask projection: {mask_aoi.crs}\")\n",
    "print(f\"Dynamic_mask projection: {mask_dynamic.crs}\")\n",
    "print(f\"ICESat-2 elevation projection: {icesat_march_may.crs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ATL06_quality_summary parameter indicates the best-quality subset of all ATL06 data. A zero in\n",
    "this parameter implies that no data-quality tests have found a problem with the segment, a one\n",
    "implies that some potential problem has been found. Users who select only segments with zero values\n",
    "for this flag can be relatively certain of obtaining high-quality data, but will likely miss a significant\n",
    "fraction of usable data, particularly in cloudy, rough, or low-surface-reflectance conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path\n",
    "output_path = 'ArcticDEM Processing/shp/merged_ATL06_march_may_filtered.shp'\n",
    "\n",
    "# Check if the file already exists before saving\n",
    "if not os.path.exists(output_path):\n",
    "    # Clip icesat data using dynamic mask and aoi\n",
    "    icesat_mar_may_aoi_clip = gpd.clip(icesat_march_may, mask_aoi)\n",
    "    icesat_mar_may_clip = icesat_mar_may_aoi_clip[~icesat_mar_may_aoi_clip.geometry.within(mask_dynamic.unary_union)]\n",
    "\n",
    "    # Filter icesat data by removing lower quality points atl06_quality_summary==1\n",
    "    icesat_mar_may_filtered = icesat_mar_may_clip[icesat_mar_may_clip['atl06_quality_summary']==0]\n",
    "\n",
    "    # Save the filtered points as a new shapefile\n",
    "    icesat_mar_may_filtered.to_file(f\"ArcticDEM Processing/shp/merged_ATL06_march_may_filtered.shp\", driver='ESRI Shapefile')\n",
    "\n",
    "    print(\"Clipped and filtered shapefile created: merged_ATL06_march_may_filtered.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Plot the clipped data\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "icesat_mar_may_filtered.plot(ax=ax, color=\"purple\")\n",
    "mask_dynamic.boundary.plot(ax=ax, color=\"black\")\n",
    "mask_aoi.boundary.plot(ax=ax, color=\"red\")\n",
    "ax.set_title(\"IceSat-2 ATL06 tracks (march-may, atl06_quality_summary==0)\", fontsize=10)\n",
    "ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define output path\n",
    "output_path = 'ArcticDEM Processing/shp/icesat2_mar_may_filter_20m_buffer.shp'\n",
    "\n",
    "# Check if the file already exists before saving\n",
    "if not os.path.exists(output_path):\n",
    "    # Ensure the GeoDataFrame has a Polar Stereographic coordinate reference system\n",
    "    icesat2_20mbuffer = icesat_mar_may_filtered.to_crs(\"EPSG:3413\") \n",
    "\n",
    "    # Create a 20m buffer around each point\n",
    "    icesat2_20mbuffer['geometry'] = icesat2_20mbuffer.geometry.buffer(20)\n",
    "    \n",
    "    icesat2_20mbuffer.to_file(output_path, driver=\"ESRI Shapefile\")\n",
    "    print(f\"Buffered shapefile created: {os.path.basename(output_path)}\")\n",
    "else:\n",
    "    print(f\"File already exists and was not overwritten: {os.path.basename(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each clipped ArcticDEM tif, extract elevation within 20m buffered point and calculate the mean elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features into GeoDataFrame\n",
    "def create_geodataframe(features):\n",
    "    geometries = []\n",
    "    properties = []\n",
    "    for feature in features:\n",
    "        geometries.append(shape(feature['geometry']))\n",
    "        properties.append(feature['properties'])\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(properties, geometry=geometries)\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_file = \"ArcticDEM Processing/csv/zonal_stats_20mbuffer_icesat2_filtered.csv\"\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(zonal_stats_file):\n",
    "    # List to store zonal stats for all DEMs\n",
    "    zonal_stats_all = []\n",
    "\n",
    "    # Iterate over each masked DEM\n",
    "    for dem_file in os.listdir(clipped_dem_folder):\n",
    "        if dem_file.endswith(\".tif\"):\n",
    "            dem_path = os.path.join(clipped_dem_folder, dem_file)\n",
    "            print(f\"Processing {dem_file}...\")\n",
    "\n",
    "            with rasterio.open(dem_path) as src:\n",
    "                # Align CRS\n",
    "                icesat2_points = icesat2_20mbuffer.to_crs(src.crs)\n",
    "\n",
    "                # Check for overlap\n",
    "                raster_bounds = box(*src.bounds)\n",
    "                buffered_extent = icesat2_20mbuffer.geometry.unary_union\n",
    "\n",
    "                if not raster_bounds.intersects(buffered_extent):\n",
    "                    print(f\"No overlap between {dem_file} and buffered points. Skipping...\")\n",
    "                    continue\n",
    "\n",
    "                # Retrieve NoData value\n",
    "                nodata_value = src.nodata\n",
    "                if nodata_value is None:\n",
    "                    nodata_value = -9999  # Set a default if not defined\n",
    "\n",
    "                # Compute zonal stats\n",
    "                stats = zonal_stats(\n",
    "                    vectors=icesat2_points,  # Buffered points\n",
    "                    raster=dem_path,\n",
    "                    stats=[\"mean\", \"max\", \"min\", \"std\", \"count\"],\n",
    "                    geojson_out=True,\n",
    "                    copy_properties=True,\n",
    "                    all_touched=True,\n",
    "                    nodata=nodata_value  # Exclude NoData values\n",
    "                )\n",
    "\n",
    "                # Add file information to stats\n",
    "                fileid = os.path.splitext(dem_file)[0]\n",
    "                for stat in stats:\n",
    "                    # Ensure `properties` exists and add custom attributes\n",
    "                    if \"properties\" not in stat:\n",
    "                        stat[\"properties\"] = {}\n",
    "                    stat[\"properties\"][\"DEM\"] = dem_file\n",
    "                    stat[\"properties\"][\"fileid\"] = fileid\n",
    "\n",
    "                # Append to list\n",
    "                zonal_stats_all.extend(stats)\n",
    "\n",
    "    # Create the GeoDataFrame\n",
    "    zonal_stats_gdf = create_geodataframe(zonal_stats_all)\n",
    "\n",
    "    # Save results to a CSV\n",
    "    zonal_stats_gdf.to_csv(zonal_stats_file, index=False)\n",
    "    print(f\"Zonal statistics saved to {zonal_stats_file}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"Zonal statistics already exists: {os.path.basename(zonal_stats_file)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_df = pd.read_csv(zonal_stats_file)\n",
    "\n",
    "# Check if your CSV has latitude and longitude columns\n",
    "latitude_column = 'latitude'\n",
    "longitude_column = 'longitude'\n",
    "\n",
    "# Create a GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(zonal_stats_df[longitude_column], zonal_stats_df[latitude_column])]\n",
    "geo_df = gpd.GeoDataFrame(zonal_stats_df, geometry=geometry, crs=\"EPSG:4326\")  # WGS84\n",
    "\n",
    "# Transform to Polar Stereographic\n",
    "geo_df_polar = geo_df.to_crs(\"EPSG:3413\")\n",
    "\n",
    "zonal_stats_gdf = gpd.GeoDataFrame(geo_df_polar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the ArcticDEM raster\n",
    "example_raster = \"SETSM_s2s041_WV02_20120821_103001001C45DA00_103001001B312B00_2m_lsf_seg2_dem.tif\"\n",
    "\n",
    "with rasterio.open(\"ArcticDEM Processing/3_clip/\"+ example_raster) as src:\n",
    "    # Read the DEM data (assuming it has a single band)\n",
    "    dem_data = src.read(1)  # Reads the first band\n",
    "    \n",
    "    # Replace null values (-9999) with NaN\n",
    "    dem_data = np.where(dem_data == -9999, np.nan, dem_data)\n",
    "    \n",
    "    # Get the affine transform to map row/column indices to spatial coordinates (eastings/northings)\n",
    "    transform = src.transform\n",
    "    \n",
    "    # Mask the DEM to focus on valid data points (non-NaN values)\n",
    "    dem_masked = np.ma.masked_invalid(dem_data)  # Mask invalid (NaN) values\n",
    "\n",
    "    # Get the eastings and northings for each pixel\n",
    "    rows, cols = np.where(~dem_masked.mask)  # Find the valid pixels (non-masked)\n",
    "    \n",
    "    # Convert pixel row/col indices to geographic coordinates (eastings and northings)\n",
    "    eastings, northings = src.xy(rows, cols)\n",
    "\n",
    "icesat_dem_extract = zonal_stats_gdf[zonal_stats_gdf['DEM'] == example_raster]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ep.plot_bands(dem_data,\n",
    "              extent=plotting_extent(src), # Set spatial extent \n",
    "              cmap='Greys',\n",
    "              title=f\"ICESat-2 filtered points \\n ArcticDEM {datetime.strptime(example_raster.split(\"_\")[3], \"%Y%m%d\").date()}\",\n",
    "              scale=False,\n",
    "              ax=ax)\n",
    "\n",
    "icesat_dem_extract.plot(ax=ax,\n",
    "                       marker='s',\n",
    "                       markersize=10,\n",
    "                       color='purple')\n",
    "ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_gdf_dropna = zonal_stats_gdf.dropna(subset=['mean'])\n",
    "\n",
    "zonal_stats_gdf_dropna['x'] = zonal_stats_gdf_dropna.geometry.centroid.x\n",
    "zonal_stats_gdf_dropna['y'] = zonal_stats_gdf_dropna.geometry.centroid.y\n",
    "\n",
    "# Use x, y, and DEM elevation as predictors\n",
    "X = zonal_stats_gdf_dropna[['x', 'y', 'mean']].values\n",
    "y = y = zonal_stats_gdf_dropna['mean'] - zonal_stats_gdf_dropna['h_li'].values # Difference between ICESat-2 and ArcticDEM\n",
    "\n",
    "# Fit a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Regression coefficients:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove ICESat-2 outliers where values are more than 3 standard deviatioins away from the mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_gdf_dropna = zonal_stats_gdf.dropna(subset=['mean'])\n",
    "\n",
    "# Calculate the mean and standard deviation of the ICESat-2 elevations\n",
    "# Define the range for valid elevations (within 3 standard deviations from the mean)\n",
    "lower_bound = zonal_stats_gdf_dropna['h_li'].mean() - 3 * zonal_stats_gdf_dropna['h_li'].std()\n",
    "upper_bound = zonal_stats_gdf_dropna['h_li'].mean() + 3 * zonal_stats_gdf_dropna['h_li'].std()\n",
    "\n",
    "# Filter out the outliers by checking if the elevations are within the valid range\n",
    "valid_elevations_mask = (zonal_stats_gdf_dropna['h_li'] >= lower_bound) & (zonal_stats_gdf_dropna['h_li'] <= upper_bound)\n",
    "zonal_stats_gdf_filtered = zonal_stats_gdf_dropna[valid_elevations_mask]\n",
    "\n",
    "# Calculate x/y from geometry\n",
    "zonal_stats_gdf_filtered['x'] = zonal_stats_gdf_filtered.geometry.centroid.x\n",
    "zonal_stats_gdf_filtered['y'] = zonal_stats_gdf_filtered.geometry.centroid.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a modeled DEM using linear regression parameters obtained from the ICESat-2 elevation differences.\n",
    "The \"modelled DEM\" should represent a plane generated using the regression model's coefficients over the entire DEM extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dem(file_path):\n",
    "    \"\"\"Load DEM file and return metadata, data, and coordinate grid.\"\"\"\n",
    "    with rasterio.open(file_path) as src:\n",
    "        meta = src.meta\n",
    "        meta.update(dtype='float32')\n",
    "        transform = src.transform\n",
    "        height, width = src.height, src.width\n",
    "\n",
    "        x_coords, y_coords = np.meshgrid(\n",
    "            np.arange(width) * transform[0] + transform[2],\n",
    "            np.arange(height) * transform[4] + transform[5]\n",
    "        )\n",
    "\n",
    "        dem_data = src.read(1)\n",
    "        dem_data = np.where(dem_data == -9999, np.nan, dem_data)\n",
    "\n",
    "        return meta, dem_data, x_coords, y_coords\n",
    "\n",
    "def correct_dem(dem_data, x_coords, y_coords, reg_model):\n",
    "    \"\"\"Apply the regression model to correct the DEM.\"\"\"\n",
    "    x_residual = x_coords - np.nanmean(x_coords)\n",
    "    y_residual = y_coords - np.nanmean(y_coords)\n",
    "\n",
    "    modelled_dz = (reg_model.coef_[0] * x_residual) + (reg_model.coef_[1] * y_residual) + reg_model.intercept_\n",
    "    return dem_data + modelled_dz, modelled_dz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all .tif files in the input folder\n",
    "for file_name in os.listdir(clipped_dem_folder):\n",
    "    if file_name.endswith(\".tif\"):\n",
    "        clipped_dem_path = os.path.join(clipped_dem_folder, file_name)\n",
    "        corrected_dem_path = os.path.join(corrected_dem_folder, file_name)\n",
    "\n",
    "        # Check if output file exists and is valid\n",
    "        if os.path.exists(corrected_dem_path) and os.path.getsize(corrected_dem_path) > 0:\n",
    "            print(f\"Skipping {file_name}: Output file already exists and is >0MB.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {file_name}...\")\n",
    "\n",
    "        try:\n",
    "            # Load DEM file and return metadata, data, and coordinate grid\n",
    "            meta, dem_data, x_coords, y_coords = load_dem(clipped_dem_path)\n",
    "\n",
    "            # Linear regression setup\n",
    "            x = zonal_stats_gdf_filtered[\"x\"].values - np.nanmean(x_coords)\n",
    "            y = zonal_stats_gdf_filtered[\"y\"].values - np.nanmean(y_coords)\n",
    "            Y = zonal_stats_gdf_filtered[\"h_li\"] - zonal_stats_gdf_filtered['mean']\n",
    "\n",
    "            mask = ~np.isnan(Y)\n",
    "            X = np.stack([x, y], axis=1)[mask]\n",
    "            Y = Y[mask]\n",
    "\n",
    "            reg_model = LinearRegression().fit(X, Y)\n",
    "            print(\"Regression score:\", reg_model.score(X, Y))\n",
    "            print(\"Coefficients:\", reg_model.coef_)\n",
    "            print(\"Intercept:\", reg_model.intercept_)\n",
    "\n",
    "            # Apply the regression model to correct the DEM\n",
    "            corrected_dem, modelled_dz = correct_dem(dem_data, x_coords, y_coords, reg_model)\n",
    "\n",
    "            # Save the corrected DEM to the specified path\n",
    "            meta.update(dtype=corrected_dem.dtype)\n",
    "            with rasterio.open(corrected_dem_path, \"w\", **meta) as dst:\n",
    "                dst.write(corrected_dem, 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "print(\"DEM correction completed for all files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "\n",
    "ep.plot_bands(dem_data,\n",
    "              extent=plotting_extent(src), # Set spatial extent \n",
    "              cmap='Greys',\n",
    "              title=\"original dem \",\n",
    "              scale=False,\n",
    "              ax=ax[0])\n",
    "\n",
    "ep.plot_bands(modelled_dz,\n",
    "              extent=plotting_extent(src), # Set spatial extent \n",
    "              cmap='Greys',\n",
    "              title=\"modelled dem \",\n",
    "              scale=False,\n",
    "              ax=ax[1])\n",
    "\n",
    "ep.plot_bands(corrected_dem,\n",
    "              extent=plotting_extent(src), # Set spatial extent \n",
    "              cmap='Greys',\n",
    "              title=\"corrected dem \",\n",
    "              scale=False,\n",
    "              ax=ax[2])\n",
    "\n",
    "ep.plot_bands(dem_data-corrected_dem,\n",
    "              extent=plotting_extent(src), # Set spatial extent \n",
    "              cmap='RdBu',\n",
    "              title=\"difference dem \",\n",
    "              scale=False,\n",
    "              ax=ax[3])\n",
    "\n",
    "# icesat_mar_may_clip_Polar_Stereographic.plot(ax=ax[1],\n",
    "#                        marker='s',\n",
    "#                        markersize=10,\n",
    "#                        color='purple')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
